# ğŸŒ¦ï¸ Weather Data Pipeline
An end-to-end Python pipeline that fetches hourly weather data from a public API, processes it using Pandas, and stores the results in both a local SQLite database and Parquet format. Ideal for practicing data engineering concepts such as data ingestion, transformation, and storage.


Repository Name: weather_data_pipeline

ğŸ”¸ Description:
An end-to-end Python pipeline that fetches hourly weather data from a public API, processes it using Pandas, and stores the results in both a local SQLite database and Parquet format. Ideal for practicing data engineering concepts such as data ingestion, transformation, and storage.

---

## ğŸš€ Features

- âœ… Fetches hourly weather data using an open API  
- âœ… Transforms and cleans the data using `pandas`  
- âœ… Saves data to:
  - Local SQLite database (`weather.db`)
  - Parquet file (`data/processed/weather.parquet`)  
- âœ… Modular pipeline structure (ETL style)
- âœ… Data exploration script included

---

## ğŸ—ï¸ Project Structure

weather_data_pipeline/
â”‚
â”œâ”€â”€ data/                       # Raw and processed data
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ logs/                       # Log files
â”‚
â”œâ”€â”€ config/                     # API keys, DB creds
â”‚   â””â”€â”€ config.env
â”‚
â”œâ”€â”€ pipeline/                   # Core ETL code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ingest.py               # API calls
â”‚   â”œâ”€â”€ transform.py            # Clean & transform data
â”‚   â”œâ”€â”€ load.py                 # Save to DB / Parquet
â”‚
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ run_pipeline.py             # Main script to run pipeline
â”œâ”€â”€ explore_data.py             # analyze saved weather data:
â””â”€â”€ README.md                   # Project overview

# Requirements
Python 3.10+
Libraries:
pandas
requests
sqlalchemy
pyarrow or fastparquet

ğŸŒ API Used
Open-Meteo: https://open-meteo.com/
Free weather API (no authentication required)



